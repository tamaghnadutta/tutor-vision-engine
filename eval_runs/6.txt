(env) tamaghnadutta@Tamaghnas-MacBook-Air tutor-vision-engine % make eval
python scripts/run_eval.py
/Users/tamaghnadutta/.pyenv/versions/3.10.2/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:404: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.
  warn(
2025-09-13 20:31:44 - __main__ - INFO - Starting comprehensive evaluation with all three approaches
2025-09-13 20:31:44 - src.data.dataset - INFO - Loaded 4 samples from dataset
2025-09-13 20:31:44 - __main__ - INFO - Evaluating OCR→LLM approach (GPT-4V OCR → GPT-4o/Gemini reasoning)
2025-09-13 20:31:44 - src.models.error_detection_approaches - INFO - Initialized OCR→LLM: GPT-4V (OCR) → openai (reasoning)
2025-09-13 20:31:44 - src.models.gemini_processor - INFO - Initialized Gemini client successfully
2025-09-13 20:31:44 - src.models.robust_model_router - INFO - Initialized RobustMultiModelProcessor with openai provider
2025-09-13 20:31:44 - src.models.error_detector - INFO - Initialized ErrorDetector with 'ocr_llm' approach
2025-09-13 20:31:44 - src.eval.evaluator - INFO - Starting evaluation of ocr_llm_approach
2025-09-13 20:31:44 - src.models.error_detection_approaches - INFO - Starting parallel OCR extraction with GPT-4V...
2025-09-13 20:31:44 - src.models.error_detection_approaches - INFO - Starting parallel OCR extraction with GPT-4V...
2025-09-13 20:31:48 - src.models.error_detection_approaches - INFO - OCR extraction completed
2025-09-13 20:31:48 - src.models.error_detection_approaches - INFO - Starting reasoning analysis with openai
2025-09-13 20:31:51 - src.models.error_detection_approaches - INFO - OCR→LLM approach completed in 6.90s
2025-09-13 20:31:51 - src.models.error_detector - INFO - Error detection completed using 'ocr_llm': has_error=True, confidence=0.950, duration=6.93s
2025-09-13 20:31:51 - src.models.error_detection_approaches - INFO - Starting parallel OCR extraction with GPT-4V...
2025-09-13 20:31:52 - src.models.error_detection_approaches - INFO - OCR extraction completed
2025-09-13 20:31:52 - src.models.error_detection_approaches - INFO - Starting reasoning analysis with openai
2025-09-13 20:31:54 - src.models.error_detection_approaches - INFO - OCR extraction completed
2025-09-13 20:31:54 - src.models.error_detection_approaches - INFO - Starting reasoning analysis with openai
2025-09-13 20:31:56 - src.models.error_detection_approaches - INFO - OCR→LLM approach completed in 12.27s
2025-09-13 20:31:56 - src.models.error_detector - INFO - Error detection completed using 'ocr_llm': has_error=True, confidence=0.950, duration=12.30s
2025-09-13 20:31:56 - src.models.error_detection_approaches - INFO - Starting parallel OCR extraction with GPT-4V...
2025-09-13 20:31:58 - src.models.error_detection_approaches - INFO - OCR→LLM approach completed in 7.33s
2025-09-13 20:31:58 - src.models.error_detector - INFO - Error detection completed using 'ocr_llm': has_error=True, confidence=0.950, duration=7.36s
2025-09-13 20:32:02 - src.models.error_detection_approaches - INFO - OCR extraction completed
2025-09-13 20:32:02 - src.models.error_detection_approaches - INFO - Starting reasoning analysis with openai
2025-09-13 20:32:05 - src.models.error_detection_approaches - INFO - OCR→LLM approach completed in 9.03s
2025-09-13 20:32:05 - src.models.error_detector - INFO - Error detection completed using 'ocr_llm': has_error=True, confidence=0.950, duration=9.06s
2025-09-13 20:32:05 - src.eval.evaluator - INFO - Evaluation completed for ocr_llm_approach: accuracy=0.750, latency_p95=12.31s
2025-09-13 20:32:05 - __main__ - INFO - Evaluating Direct VLM approach (GPT-4V or Gemini-2.5-Flash single call)
2025-09-13 20:32:05 - src.models.error_detection_approaches - INFO - Initialized Direct VLM approach with openai
2025-09-13 20:32:05 - src.models.gemini_processor - INFO - Initialized Gemini client successfully
2025-09-13 20:32:05 - src.models.robust_model_router - INFO - Initialized RobustMultiModelProcessor with openai provider
2025-09-13 20:32:05 - src.models.error_detector - INFO - Initialized ErrorDetector with 'vlm_direct' approach
2025-09-13 20:32:05 - src.eval.evaluator - INFO - Starting evaluation of vlm_direct_approach
2025-09-13 20:32:16 - src.models.error_detection_approaches - INFO - Direct VLM approach completed in 10.81s
2025-09-13 20:32:16 - src.models.error_detector - INFO - Error detection completed using 'vlm_direct': has_error=True, confidence=0.950, duration=10.83s
2025-09-13 20:32:20 - src.models.error_detection_approaches - INFO - Direct VLM approach completed in 15.01s
2025-09-13 20:32:20 - src.models.error_detector - INFO - Error detection completed using 'vlm_direct': has_error=True, confidence=0.900, duration=15.04s
2025-09-13 20:32:29 - src.models.error_detection_approaches - INFO - Direct VLM approach completed in 12.56s
2025-09-13 20:32:29 - src.models.error_detector - INFO - Error detection completed using 'vlm_direct': has_error=True, confidence=0.950, duration=12.60s
2025-09-13 20:32:39 - src.models.error_detection_approaches - INFO - Direct VLM approach completed in 18.40s
2025-09-13 20:32:39 - src.models.error_detector - INFO - Error detection completed using 'vlm_direct': has_error=True, confidence=0.950, duration=18.43s
2025-09-13 20:32:39 - src.eval.evaluator - INFO - Evaluation completed for vlm_direct_approach: accuracy=0.750, latency_p95=18.43s
2025-09-13 20:32:39 - __main__ - INFO - Evaluating Hybrid approach (OCR→LLM + Direct VLM ensemble)
2025-09-13 20:32:39 - src.models.error_detection_approaches - INFO - Initialized OCR→LLM: GPT-4V (OCR) → openai (reasoning)
2025-09-13 20:32:39 - src.models.error_detection_approaches - INFO - Initialized Direct VLM approach with openai
2025-09-13 20:32:39 - src.models.error_detection_approaches - INFO - Initialized Hybrid approach (OCR→LLM + Direct VLM)
2025-09-13 20:32:39 - src.models.gemini_processor - INFO - Initialized Gemini client successfully
2025-09-13 20:32:39 - src.models.robust_model_router - INFO - Initialized RobustMultiModelProcessor with openai provider
2025-09-13 20:32:39 - src.models.error_detector - INFO - Initialized ErrorDetector with 'hybrid' approach
2025-09-13 20:32:39 - src.eval.evaluator - INFO - Starting evaluation of hybrid_approach
2025-09-13 20:32:39 - src.models.error_detection_approaches - INFO - Starting parallel execution of OCR→LLM and Direct VLM approaches...
2025-09-13 20:32:39 - src.models.error_detection_approaches - INFO - Starting parallel OCR extraction with GPT-4V...
2025-09-13 20:32:39 - src.models.error_detection_approaches - INFO - Starting parallel execution of OCR→LLM and Direct VLM approaches...
2025-09-13 20:32:39 - src.models.error_detection_approaches - INFO - Starting parallel OCR extraction with GPT-4V...
2025-09-13 20:32:42 - src.models.error_detection_approaches - INFO - OCR extraction completed
2025-09-13 20:32:42 - src.models.error_detection_approaches - INFO - Starting reasoning analysis with openai
2025-09-13 20:32:44 - src.models.error_detection_approaches - INFO - OCR→LLM approach completed in 5.55s
2025-09-13 20:32:47 - src.models.error_detection_approaches - INFO - OCR extraction completed
2025-09-13 20:32:47 - src.models.error_detection_approaches - INFO - Starting reasoning analysis with openai
2025-09-13 20:32:52 - src.models.error_detection_approaches - INFO - OCR→LLM approach completed in 13.03s
2025-09-13 20:32:52 - src.models.error_detection_approaches - INFO - Direct VLM approach completed in 13.33s
2025-09-13 20:32:52 - src.models.error_detection_approaches - INFO - Both approaches completed, starting ensemble...
2025-09-13 20:32:52 - src.models.error_detection_approaches - INFO - Ensembling results: OCR→LLM confidence=0.950, Direct VLM confidence=0.950
2025-09-13 20:32:52 - src.models.error_detection_approaches - INFO - Both approaches agree (error=True), using OCR→LLM
2025-09-13 20:32:52 - src.models.error_detection_approaches - INFO - Hybrid approach completed in 13.34s
2025-09-13 20:32:52 - src.models.error_detector - INFO - Error detection completed using 'hybrid': has_error=True, confidence=0.950, duration=13.36s
2025-09-13 20:32:52 - src.models.error_detection_approaches - INFO - Starting parallel execution of OCR→LLM and Direct VLM approaches...
2025-09-13 20:32:52 - src.models.error_detection_approaches - INFO - Starting parallel OCR extraction with GPT-4V...
2025-09-13 20:32:56 - src.models.error_detection_approaches - INFO - OCR extraction completed
2025-09-13 20:32:56 - src.models.error_detection_approaches - INFO - Starting reasoning analysis with openai
2025-09-13 20:33:00 - src.models.error_detection_approaches - INFO - OCR→LLM approach completed in 8.00s
2025-09-13 20:33:03 - src.models.error_detection_approaches - INFO - Direct VLM approach completed in 24.19s
2025-09-13 20:33:03 - src.models.error_detection_approaches - INFO - Both approaches completed, starting ensemble...
2025-09-13 20:33:03 - src.models.error_detection_approaches - INFO - Ensembling results: OCR→LLM confidence=0.950, Direct VLM confidence=0.950
2025-09-13 20:33:03 - src.models.error_detection_approaches - INFO - Both approaches agree (error=True), using OCR→LLM
2025-09-13 20:33:03 - src.models.error_detection_approaches - INFO - Hybrid approach completed in 24.19s
2025-09-13 20:33:03 - src.models.error_detector - INFO - Error detection completed using 'hybrid': has_error=True, confidence=0.950, duration=24.22s
2025-09-13 20:33:03 - src.models.error_detection_approaches - INFO - Starting parallel execution of OCR→LLM and Direct VLM approaches...
2025-09-13 20:33:03 - src.models.error_detection_approaches - INFO - Starting parallel OCR extraction with GPT-4V...
2025-09-13 20:33:04 - src.models.error_detection_approaches - INFO - Direct VLM approach completed in 12.05s
2025-09-13 20:33:04 - src.models.error_detection_approaches - INFO - Both approaches completed, starting ensemble...
2025-09-13 20:33:04 - src.models.error_detection_approaches - INFO - Ensembling results: OCR→LLM confidence=0.950, Direct VLM confidence=0.950
2025-09-13 20:33:04 - src.models.error_detection_approaches - INFO - Both approaches agree (error=True), using OCR→LLM
2025-09-13 20:33:04 - src.models.error_detection_approaches - INFO - Hybrid approach completed in 12.05s
2025-09-13 20:33:04 - src.models.error_detector - INFO - Error detection completed using 'hybrid': has_error=True, confidence=0.950, duration=12.07s
2025-09-13 20:33:10 - src.models.error_detection_approaches - INFO - OCR extraction completed
2025-09-13 20:33:10 - src.models.error_detection_approaches - INFO - Starting reasoning analysis with openai
2025-09-13 20:33:13 - src.models.error_detection_approaches - INFO - OCR→LLM approach completed in 10.31s
2025-09-13 20:33:24 - src.models.error_detection_approaches - INFO - Direct VLM approach completed in 20.96s
2025-09-13 20:33:24 - src.models.error_detection_approaches - INFO - Both approaches completed, starting ensemble...
2025-09-13 20:33:24 - src.models.error_detection_approaches - INFO - Ensembling results: OCR→LLM confidence=0.950, Direct VLM confidence=0.950
2025-09-13 20:33:24 - src.models.error_detection_approaches - INFO - Both approaches agree (error=True), using OCR→LLM
2025-09-13 20:33:24 - src.models.error_detection_approaches - INFO - Hybrid approach completed in 20.96s
2025-09-13 20:33:24 - src.models.error_detector - INFO - Error detection completed using 'hybrid': has_error=True, confidence=0.950, duration=20.99s
2025-09-13 20:33:24 - src.eval.evaluator - INFO - Evaluation completed for hybrid_approach: accuracy=0.750, latency_p95=24.22s
2025-09-13 20:33:24 - __main__ - INFO - Results saved to ./data/eval_results/evaluation_results.json

====================================================================================================
ERROR DETECTION API - COMPREHENSIVE EVALUATION RESULTS
====================================================================================================

Core Performance Metrics:
+---------------------+-----------+--------------+----------+-----------------+
| Metric              |   OCR→LLM |   Direct VLM |   Hybrid | Best Approach   |
+=====================+===========+==============+==========+=================+
| Accuracy            |     0.75  |        0.75  |    0.75  | OCR→LLM (0.750) |
+---------------------+-----------+--------------+----------+-----------------+
| F1 Score            |     0.857 |        0.857 |    0.857 | OCR→LLM (0.857) |
+---------------------+-----------+--------------+----------+-----------------+
| Precision           |     0.75  |        0.75  |    0.75  | OCR→LLM (0.750) |
+---------------------+-----------+--------------+----------+-----------------+
| Recall              |     1     |        1     |    1     | OCR→LLM (1.000) |
+---------------------+-----------+--------------+----------+-----------------+
| Step-Level Accuracy |     0.704 |        0.704 |    0.704 | OCR→LLM (0.704) |
+---------------------+-----------+--------------+----------+-----------------+

Latency Metrics (seconds):
+--------------+-----------+--------------+----------+--------------------+
| Percentile   |   OCR→LLM |   Direct VLM |   Hybrid | Best Performance   |
+==============+===========+==============+==========+====================+
| p50          |      9.06 |        15.04 |    20.99 | OCR→LLM (9.06s)    |
+--------------+-----------+--------------+----------+--------------------+
| p90          |     12.31 |        18.43 |    24.22 | OCR→LLM (12.31s)   |
+--------------+-----------+--------------+----------+--------------------+
| p95          |     12.31 |        18.43 |    24.22 | OCR→LLM (12.31s)   |
+--------------+-----------+--------------+----------+--------------------+

Comprehensive Ablation Study:

1. Baseline (Direct VLM) vs Primary Improvement (Hybrid):
+-------------+-------------------------+---------------------+---------------+
| Metric      | Baseline (Direct VLM)   | Improved (Hybrid)   | Improvement   |
+=============+=========================+=====================+===============+
| Accuracy    | 0.750                   | 0.750               | +0.000        |
+-------------+-------------------------+---------------------+---------------+
| F1 Score    | 0.857                   | 0.857               | +0.000        |
+-------------+-------------------------+---------------------+---------------+
| Latency p95 | 18.43s                  | 24.22s              | -5.79s        |
+-------------+-------------------------+---------------------+---------------+

2. OCR→LLM vs Baseline (Direct VLM):
+-------------+-------------------------+-----------+--------------+
| Metric      | Direct VLM (Baseline)   | OCR→LLM   | Difference   |
+=============+=========================+===========+==============+
| Accuracy    | 0.750                   | 0.750     | +0.000       |
+-------------+-------------------------+-----------+--------------+
| F1 Score    | 0.857                   | 0.857     | +0.000       |
+-------------+-------------------------+-----------+--------------+
| Latency p95 | 18.43s                  | 12.31s    | +6.12s       |
+-------------+-------------------------+-----------+--------------+

3. Hybrid vs OCR→LLM:
+-------------+-----------+----------+---------------+
| Metric      | OCR→LLM   | Hybrid   | Improvement   |
+=============+===========+==========+===============+
| Accuracy    | 0.750     | 0.750    | +0.000        |
+-------------+-----------+----------+---------------+
| F1 Score    | 0.857     | 0.857    | +0.000        |
+-------------+-----------+----------+---------------+
| Latency p95 | 12.31s    | 24.22s   | -11.91s       |
+-------------+-----------+----------+---------------+

Cost Estimation (per 100 requests):
+-----------------------+------------------+----------------------------------------------------------------------+
| Approach              | Estimated Cost   | Notes                                                                |
+=======================+==================+======================================================================+
| Direct VLM (Baseline) | $0.90            | GPT-4V single call - most cost-effective                             |
+-----------------------+------------------+----------------------------------------------------------------------+
| OCR→LLM               | $1.07            | GPT-4V OCR + GPT-4o reasoning - 2 API calls                          |
+-----------------------+------------------+----------------------------------------------------------------------+
| Hybrid (Improvement)  | $1.98            | Both approaches + ensemble - highest cost, potentially best accuracy |
+-----------------------+------------------+----------------------------------------------------------------------+

🎯 ASSIGNMENT COMPLIANCE SUMMARY:
✅ Baseline: Direct VLM approach (single vision-language model call)
✅ Primary Improvement: Hybrid approach (ensemble of OCR→LLM + Direct VLM)
✅ Ablation Study: Comprehensive comparison across all approaches
   • Direct VLM → Hybrid: +0.000 accuracy improvement
   • Direct VLM → OCR→LLM: +0.000 accuracy difference
   • OCR→LLM → Hybrid: +0.000 accuracy improvement
✅ Latency: Hybrid p95 = 24.2s ❌ (target: ≤10s)

📊 KEY INSIGHTS:
   • Best Accuracy: Hybrid (0.750)
   • Fastest: OCR→LLM (12.3s p95)
   • Most Cost-Effective: Direct VLM (single model call)

💰 DETAILED COST ANALYSIS (Based on 2025 Pricing):

================================================================================
COST ANALYSIS REPORT - 100 REQUESTS
================================================================================
Based on current 2025 pricing (September 2025)

📊 OCR → LLM
   Description: GPT-4o OCR + GPT-4o reasoning (2 API calls)
   Cost per request: $0.010750
   Cost per 100 requests: $1.07
   API calls per request: 2
   Breakdown:
     • GPT-4o (OCR extraction): $0.005750
     • GPT-4o (Text reasoning): $0.005000

📊 VLM → DIRECT
   Description: Single GPT-4o vision call
   Cost per request: $0.009000
   Cost per 100 requests: $0.90
   API calls per request: 1
   Breakdown:
     • GPT-4o (Direct vision analysis): $0.009000

📊 VLM → DIRECT → GEMINI
   Description: Single Gemini 2.5 Flash call
   Cost per request: $0.001600
   Cost per 100 requests: $0.16
   API calls per request: 1
   Breakdown:
     • Gemini 2.5 Flash (Direct vision analysis): $0.001600

📊 HYBRID
   Description: OCR→LLM + Direct VLM ensemble (3 API calls)
   Cost per request: $0.019750
   Cost per 100 requests: $1.98
   API calls per request: 3
   Breakdown:
     • GPT-4o (OCR extraction): $0.005750
     • GPT-4o (Text reasoning): $0.005000
     • GPT-4o (Direct vision analysis): $0.009000

💡 COST INSIGHTS:
   • Cheapest: vlm → direct → gemini ($0.16 per 100)
   • Most Expensive: hybrid ($1.98 per 100)
   • Potential Savings: $1.82 per 100 requests

💰 PRICING NOTES:
   • GPT-4o: Output tokens cost 4x more than input tokens
   • Gemini 2.5 Flash: 4x price increase from preview pricing
   • Consider Gemini 2.5 Flash-Lite for cost optimization
   • Batch API can reduce costs by 50% for both models

====================================================================================================
2025-09-13 20:33:24 - __main__ - INFO - Evaluation completed successfully
(env) tamaghnadutta@Tamaghnas-MacBook-Air tutor-vision-engine % 